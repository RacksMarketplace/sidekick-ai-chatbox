import "dotenv/config";
import { app, BrowserWindow, globalShortcut, ipcMain } from "electron";
import path from "path";
import fs from "fs";

type ChatContentPart =
  | { type: "text"; text: string }
  | { type: "image_url"; image_url: { url: string } };

type ChatMessage = {
  role: "system" | "user" | "assistant";
  content: string | ChatContentPart[];
};

type Memory = {
  updatedAt: number;
  facts: string[];
};

let mainWindow: BrowserWindow | null = null;

// -------------------- STORAGE --------------------

function getDataDir() {
  const dir = app.getPath("userData");
  if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true });
  return dir;
}

function getHistoryPath() {
  return path.join(getDataDir(), "chat_history.json");
}

function isValidChatContent(content: unknown): content is string | ChatContentPart[] {
  if (typeof content === "string") return true;
  if (!Array.isArray(content)) return false;
  return content.every((part) => {
    if (!part || typeof part !== "object") return false;
    if ((part as ChatContentPart).type === "text") {
      return typeof (part as { text?: unknown }).text === "string";
    }
    if ((part as ChatContentPart).type === "image_url") {
      const url = (part as { image_url?: { url?: unknown } }).image_url?.url;
      return typeof url === "string";
    }
    return false;
  });
}

function readHistory(): ChatMessage[] {
  try {
    const p = getHistoryPath();
    if (!fs.existsSync(p)) return [];
    const raw = fs.readFileSync(p, "utf-8");
    const parsed = JSON.parse(raw);
    if (!Array.isArray(parsed)) return [];
    return parsed.filter(
      (m) =>
        m &&
        (m.role === "user" || m.role === "assistant" || m.role === "system") &&
        isValidChatContent(m.content)
    );
  } catch {
    return [];
  }
}

function writeHistory(messages: ChatMessage[]) {
  fs.writeFileSync(getHistoryPath(), JSON.stringify(messages, null, 2), "utf-8");
}

// -------------------- MEMORY (PERSISTENT) --------------------

function getMemoryPath() {
  return path.join(getDataDir(), "memory.json");
}

function readMemory(): Memory {
  try {
    const p = getMemoryPath();
    if (!fs.existsSync(p)) return { updatedAt: Date.now(), facts: [] };

    const raw = fs.readFileSync(p, "utf-8");
    const parsed = JSON.parse(raw);

    const facts = Array.isArray(parsed?.facts) ? parsed.facts.map(String) : [];
    const updatedAt = Number(parsed?.updatedAt) || Date.now();

    return { updatedAt, facts };
  } catch {
    return { updatedAt: Date.now(), facts: [] };
  }
}

function writeMemory(mem: Memory) {
  const next: Memory = { ...mem, updatedAt: Date.now() };
  fs.writeFileSync(getMemoryPath(), JSON.stringify(next, null, 2), "utf-8");
}

// -------------------- PROMPT --------------------

function buildSystemPrompt(mem: Memory) {
  const memoryBlock =
    mem.facts.length > 0
      ? `Memory (persistent facts):\n- ${mem.facts.join("\n- ")}`
      : "Memory (persistent facts):\n- (none yet)";

  return [
    "You are Sidekick, a lively but grounded desktop companion.",
    "Keep responses friendly, concise, and natural.",
    "No emojis. No robotic disclaimers. No roleplay.",
    "",
    memoryBlock,
    "",
    "Vision rules (mandatory):",
    "- You only have visual access if an image is attached in the current user message.",
    "- If no image is attached and the user asks about visuals, say you cannot see anything and invite them to upload an image.",
    "- Never imply background or ongoing visual access.",
  ].join("\n");
}

// -------------------- WINDOW --------------------

function createWindow() {
  mainWindow = new BrowserWindow({
    width: 420,
    height: 560,
    show: true,
    frame: false,
    alwaysOnTop: true,
    transparent: true,
    resizable: true,
    webPreferences: {
      preload: path.join(__dirname, "preload.js"),
      contextIsolation: true,
      nodeIntegration: false,
    },
  });

  const url =
    process.env.VITE_DEV_SERVER_URL ||
    `file://${path.join(__dirname, "../renderer/index.html")}`;

  mainWindow.loadURL(url);

  mainWindow.on("closed", () => {
    mainWindow = null;
  });
}

// -------------------- TOGGLE WINDOW --------------------

function toggleWindow() {
  if (!mainWindow) return;

  if (mainWindow.isVisible()) {
    mainWindow.hide();
    return;
  }

  mainWindow.show();
  mainWindow.focus();
}

// -------------------- APP --------------------

app.whenReady().then(() => {
  createWindow();
  globalShortcut.register("Control+Shift+Space", toggleWindow);
});

app.on("window-all-closed", () => {});

// -------------------- IPC: HISTORY --------------------
// "New chat" resets UI history, but memory stays.

ipcMain.handle("history:load", async () => readHistory());

ipcMain.handle("history:clear", async () => {
  writeHistory([]);
  return true;
});

// -------------------- IPC: MEMORY --------------------

ipcMain.handle("memory:get", async () => readMemory());

ipcMain.handle("memory:addFact", async (_e, fact: string) => {
  const trimmed = (fact || "").trim();
  const mem = readMemory();
  if (!trimmed) return mem;

  if (!mem.facts.includes(trimmed)) {
    mem.facts.unshift(trimmed);
    mem.facts = mem.facts.slice(0, 50);
    writeMemory(mem);
  }
  return readMemory();
});

// -------------------- IPC: AI CHAT --------------------

ipcMain.handle("ai:chat", async (_event, messages: ChatMessage[]) => {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) throw new Error("OPENAI_API_KEY not set");

  writeHistory(messages.filter((m) => m.role !== "system"));

  const mem = readMemory();
  const systemPrompt = buildSystemPrompt(mem);

  const filteredMessages = messages.filter((m) => m.role !== "system");

  const payload: ChatMessage[] = [
    { role: "system", content: systemPrompt },
    ...filteredMessages,
  ];

  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: "gpt-4o-mini",
      temperature: 0.7,
      messages: payload,
    }),
  });

  const data: any = await response.json();
  if (!response.ok) throw new Error(data?.error?.message || "OpenAI request failed");

  const assistantText: string = data?.choices?.[0]?.message?.content ?? "";

  const nextHistory: ChatMessage[] = [
    ...messages.filter((m) => m.role !== "system"),
    { role: "assistant", content: assistantText },
  ];

  writeHistory(nextHistory);

  return assistantText;
});
